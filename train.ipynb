{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install: download disentanglement_lib and follow instructions to download datasets\n",
    "!git clone https://github.com/google-research/disentanglement_lib.git\n",
    "!mv disentanglement_lib disentanglement_library\n",
    "!cp -r disentanglement_lib_patch/* disentanglement_library/disentanglement_lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./disentanglement_library/')\n",
    "\n",
    "import os\n",
    "os.environ[\"DISENTANGLEMENT_LIB_DATA\"] = \"./disentanglement_library/data/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from models.model import Model\n",
    "from models.conv64 import SimpleConv64,SimpleConv64D\n",
    "\n",
    "parser = ArgumentParser(add_help=False)\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "parser.set_defaults(max_epochs=-1)\n",
    "parser.set_defaults(check_val_every_n_epoch=1)\n",
    "parser = Model.add_model_specific_args(parser)\n",
    "args = parser.parse_args(['--n_dataset','2',\n",
    "                          '--k','-1',\n",
    "                          '--latentdim','10',\n",
    "                          '--n_latent_factors', '10',\n",
    "                          '--learning_rate','5e-4',\n",
    "                          '--max_epochs','30',\n",
    "                          '--gpus','1',\n",
    "                          '--progress_bar_refresh_rate','10',\n",
    "                          '--limit_val_batches','1',\n",
    "                          '--check_val_every_n_epoch','1',\n",
    "                          '--log_every_n_steps','160',\n",
    "                           ])\n",
    "\n",
    "def train(n_dataset):\n",
    "    args.n_dataset = n_dataset\n",
    "    \n",
    "    ch=3\n",
    "    if n_dataset==0 or n_dataset==5:\n",
    "        ch=1\n",
    "    \n",
    "    model = Model(hparams=args, encoder=SimpleConv64(args.latentdim,ch,64,batch_size=args.batch_size,with_bn=False),\n",
    "                                decoder=SimpleConv64D(args.latentdim,ch,64,with_bn=False))\n",
    "    # basic trainer\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        save_last=True,\n",
    "        save_top_k=1,\n",
    "        verbose=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    run_name = 'TEST_vark_data_%d' % n_dataset\n",
    "    wandb_logger = WandbLogger(project=\"lat_geo\",log_model=True,name=run_name,reinit=True)\n",
    "    trainer = Trainer.from_argparse_args(args, logger=wandb_logger,checkpoint_callback=checkpoint_callback) #without 16 bit precision\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "train(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
